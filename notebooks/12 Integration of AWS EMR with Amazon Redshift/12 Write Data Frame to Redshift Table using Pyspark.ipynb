{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/07/14 12:55:08 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "jars = [\n",
    "    '/usr/share/aws/redshift/jdbc/RedshiftJDBC.jar',\n",
    "    '/usr/share/aws/redshift/spark-redshift/lib/spark-redshift.jar',\n",
    "    '/usr/share/aws/redshift/spark-redshift/lib/spark-avro.jar',\n",
    "    '/usr/share/aws/redshift/spark-redshift/lib/minimal-json.jar'\n",
    "]\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName('Redshift Integration'). \\\n",
    "    master('yarn'). \\\n",
    "    config('spark.jars', ','.join(jars)). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/14 12:56:18 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "ghactivity = spark.read.json('s3://aigithub/landing/ghactivity/2022-06-19*')\n",
    "ghactivity.createOrReplaceTempView('ghactivity')\n",
    "new_repos = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        repo.id AS repo_id,\n",
    "        repo.name AS repo_name,\n",
    "        actor.id AS actor_id,\n",
    "        actor.login AS actor_login,\n",
    "        actor.display_login AS actor_display_login,\n",
    "        payload.ref_type AS ref_type,\n",
    "        type,\n",
    "        created_at,\n",
    "        year(created_at) AS created_year,\n",
    "        month(created_at) AS created_month,\n",
    "        dayofmonth(created_at) AS created_dayofmonth\n",
    "    FROM ghactivity\n",
    "    WHERE type = 'CreateEvent'\n",
    "        AND payload.ref_type = 'repository'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+---------+------------------+-------------------+----------+-----------+--------------------+------------+-------------+------------------+\n",
      "|  repo_id|           repo_name| actor_id|       actor_login|actor_display_login|  ref_type|       type|          created_at|created_year|created_month|created_dayofmonth|\n",
      "+---------+--------------------+---------+------------------+-------------------+----------+-----------+--------------------+------------+-------------+------------------+\n",
      "|505110810|   Anand4311/Project|107799449|         Anand4311|          Anand4311|repository|CreateEvent|2022-06-19T13:00:01Z|        2022|            6|                19|\n",
      "|505110809|direwolf-github/e...| 10810283|   direwolf-github|    direwolf-github|repository|CreateEvent|2022-06-19T13:00:01Z|        2022|            6|                19|\n",
      "|505110811|shakil033/e-comme...| 61247278|         shakil033|          shakil033|repository|CreateEvent|2022-06-19T13:00:01Z|        2022|            6|                19|\n",
      "|505110812| happy-wq/HelloWorld| 72350545|          happy-wq|           happy-wq|repository|CreateEvent|2022-06-19T13:00:01Z|        2022|            6|                19|\n",
      "|505110815|pmamico/contribut...| 19253721|           pmamico|            pmamico|repository|CreateEvent|2022-06-19T13:00:02Z|        2022|            6|                19|\n",
      "|505110819|direwolf-github/e...| 10810283|   direwolf-github|    direwolf-github|repository|CreateEvent|2022-06-19T13:00:02Z|        2022|            6|                19|\n",
      "|505110824|efarbereger/tmp_c...|  1686007|       efarbereger|        efarbereger|repository|CreateEvent|2022-06-19T13:00:03Z|        2022|            6|                19|\n",
      "|505110823|Crystal00300/Abou...|101319712|      Crystal00300|       Crystal00300|repository|CreateEvent|2022-06-19T13:00:03Z|        2022|            6|                19|\n",
      "|505110821|enockmwizerwa123/...|105894685|  enockmwizerwa123|   enockmwizerwa123|repository|CreateEvent|2022-06-19T13:00:03Z|        2022|            6|                19|\n",
      "|505110827|Nashka92/internsh...| 95431018|          Nashka92|           Nashka92|repository|CreateEvent|2022-06-19T13:00:04Z|        2022|            6|                19|\n",
      "|505110829|    Tomi-1997/CPP_6B| 74303735|         Tomi-1997|          Tomi-1997|repository|CreateEvent|2022-06-19T13:00:05Z|        2022|            6|                19|\n",
      "|505110830|       mppp8/another| 73287152|             mppp8|              mppp8|repository|CreateEvent|2022-06-19T13:00:06Z|        2022|            6|                19|\n",
      "|505110832|     my-unix/my-unix|107799390|           my-unix|            my-unix|repository|CreateEvent|2022-06-19T13:00:06Z|        2022|            6|                19|\n",
      "|505110837|jaimebriesemeiste...| 82653221|jaimebriesemeister| jaimebriesemeister|repository|CreateEvent|2022-06-19T13:00:07Z|        2022|            6|                19|\n",
      "|505110835|  lenikoj/leniko-api|107791995|           lenikoj|            lenikoj|repository|CreateEvent|2022-06-19T13:00:07Z|        2022|            6|                19|\n",
      "|505110841|    laktebomar/geofy| 45787256|        laktebomar|         laktebomar|repository|CreateEvent|2022-06-19T13:00:08Z|        2022|            6|                19|\n",
      "|505110839|neu-mehmetkarakay...|107004466|neu-mehmetkarakaya| neu-mehmetkarakaya|repository|CreateEvent|2022-06-19T13:00:08Z|        2022|            6|                19|\n",
      "|505110843|  sree-dhar/facebook|107788401|           sree233|            sree233|repository|CreateEvent|2022-06-19T13:00:08Z|        2022|            6|                19|\n",
      "|505110845|      loginanet/JSON|103311907|         loginanet|          loginanet|repository|CreateEvent|2022-06-19T13:00:09Z|        2022|            6|                19|\n",
      "|505110846|Luceafarul/rpsls-...|  5311913|        Luceafarul|         Luceafarul|repository|CreateEvent|2022-06-19T13:00:09Z|        2022|            6|                19|\n",
      "+---------+--------------------+---------+------------------+-------------------+----------+-----------+--------------------+------------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_repos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- repo_id: long (nullable = true)\n",
      " |-- repo_name: string (nullable = true)\n",
      " |-- actor_id: long (nullable = true)\n",
      " |-- actor_login: string (nullable = true)\n",
      " |-- actor_display_login: string (nullable = true)\n",
      " |-- ref_type: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- created_year: integer (nullable = true)\n",
      " |-- created_month: integer (nullable = true)\n",
      " |-- created_dayofmonth: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_repos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "122496"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_repos.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Original logic to write to files\n",
    "new_repos. \\\n",
    "  write. \\\n",
    "  partitionBy('created_year', 'created_month', 'created_dayofmonth'). \\\n",
    "  mode('overwrite'). \\\n",
    "  parquet('s3://aigithub/github_dm/new_repos')\n",
    "```\n",
    "\n",
    "* Make sure the required permissions are granted on s3 to Redshift Cluster via IAM role.\n",
    "* Come up with the logic to write dataframe to Redshift Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "sm_client = boto3.client('secretsmanager')\n",
    "secret_value = sm_client.get_secret_value(SecretId='demo/aigithub/redshift')\n",
    "credentials = json.loads(secret_value['SecretString'])\n",
    "\n",
    "username = credentials['username']\n",
    "password = credentials['password']\n",
    "host = credentials['host']\n",
    "port = credentials['port']\n",
    "database = 'github_dm'\n",
    "url = f\"jdbc:redshift://{host}:{port}/{database}?user={username}&password={password}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "122496"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_repos.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete: s3://aigithub/temp/ghrepos/6e045934-9e62-4c11-9090-07c78c44976e/_SUCCESS\n",
      "delete: s3://aigithub/temp/ghrepos/6e045934-9e62-4c11-9090-07c78c44976e/part-00001-12071e9d-3248-4bda-a46e-8793e06ae0fc-c000.avro\n",
      "delete: s3://aigithub/temp/ghrepos/6e045934-9e62-4c11-9090-07c78c44976e/part-00006-12071e9d-3248-4bda-a46e-8793e06ae0fc-c000.avro\n",
      "delete: s3://aigithub/temp/ghrepos/6e045934-9e62-4c11-9090-07c78c44976e/part-00004-12071e9d-3248-4bda-a46e-8793e06ae0fc-c000.avro\n",
      "delete: s3://aigithub/temp/ghrepos/6e045934-9e62-4c11-9090-07c78c44976e/manifest.json\n",
      "delete: s3://aigithub/temp/ghrepos/6e045934-9e62-4c11-9090-07c78c44976e/part-00003-12071e9d-3248-4bda-a46e-8793e06ae0fc-c000.avro\n",
      "delete: s3://aigithub/temp/ghrepos/6e045934-9e62-4c11-9090-07c78c44976e/part-00007-12071e9d-3248-4bda-a46e-8793e06ae0fc-c000.avro\n",
      "delete: s3://aigithub/temp/ghrepos/6e045934-9e62-4c11-9090-07c78c44976e/part-00002-12071e9d-3248-4bda-a46e-8793e06ae0fc-c000.avro\n",
      "delete: s3://aigithub/temp/ghrepos/6e045934-9e62-4c11-9090-07c78c44976e/part-00005-12071e9d-3248-4bda-a46e-8793e06ae0fc-c000.avro\n",
      "delete: s3://aigithub/temp/ghrepos/6e045934-9e62-4c11-9090-07c78c44976e/part-00000-12071e9d-3248-4bda-a46e-8793e06ae0fc-c000.avro\n",
      "delete: s3://aigithub/temp/ghrepos/6e045934-9e62-4c11-9090-07c78c44976e/part-00008-12071e9d-3248-4bda-a46e-8793e06ae0fc-c000.avro\n"
     ]
    }
   ],
   "source": [
    "!aws s3 rm s3://aigithub/temp/ghrepos --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/14 13:03:30 WARN CredentialsLegacyConfigLocationProvider: Found the legacy config profiles file at [/home/hadoop/.aws/config]. Please move it to the latest default location [~/.aws/credentials].\n",
      "22/07/14 13:03:30 WARN Utils$: The S3 bucket aigithub does not have an object lifecycle configuration to ensure cleanup of temporary files. Consider configuring `tempdir` to point to a bucket with an object lifecycle policy that automatically deletes files after an expiration period. For more information, see https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "new_repos. \\\n",
    "    write. \\\n",
    "    mode('append'). \\\n",
    "    format('io.github.spark_redshift_community.spark.redshift'). \\\n",
    "    option(\n",
    "        'aws_iam_role', \n",
    "        'arn:aws:iam::269066542444:role/service-role/AmazonRedshift-CommandsAccessRole-20220625T110940'\n",
    "    ). \\\n",
    "    option('url', url). \\\n",
    "    option('dbtable', 'public.ghrepos'). \\\n",
    "    option('tempdir', 's3://aigithub/temp/ghrepos'). \\\n",
    "    save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://aigithub/temp/ghrepos --recursive|wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-14 12:57:45          0 temp/ghrepos/141aa32f-a7d2-4b89-b48a-123cdca01005/_SUCCESS\n",
      "2022-07-14 12:57:45       1372 temp/ghrepos/141aa32f-a7d2-4b89-b48a-123cdca01005/manifest.json\n",
      "2022-07-14 12:57:25     600396 temp/ghrepos/141aa32f-a7d2-4b89-b48a-123cdca01005/part-00000-c2fd703c-3eb1-4168-8a97-00f16ab095ca-c000.avro\n",
      "2022-07-14 12:57:25     618771 temp/ghrepos/141aa32f-a7d2-4b89-b48a-123cdca01005/part-00001-c2fd703c-3eb1-4168-8a97-00f16ab095ca-c000.avro\n",
      "2022-07-14 12:57:29     580568 temp/ghrepos/141aa32f-a7d2-4b89-b48a-123cdca01005/part-00002-c2fd703c-3eb1-4168-8a97-00f16ab095ca-c000.avro\n",
      "2022-07-14 12:57:29     489691 temp/ghrepos/141aa32f-a7d2-4b89-b48a-123cdca01005/part-00003-c2fd703c-3eb1-4168-8a97-00f16ab095ca-c000.avro\n",
      "2022-07-14 12:57:34     630458 temp/ghrepos/141aa32f-a7d2-4b89-b48a-123cdca01005/part-00004-c2fd703c-3eb1-4168-8a97-00f16ab095ca-c000.avro\n",
      "2022-07-14 12:57:34     684348 temp/ghrepos/141aa32f-a7d2-4b89-b48a-123cdca01005/part-00005-c2fd703c-3eb1-4168-8a97-00f16ab095ca-c000.avro\n",
      "2022-07-14 12:57:39     593220 temp/ghrepos/141aa32f-a7d2-4b89-b48a-123cdca01005/part-00006-c2fd703c-3eb1-4168-8a97-00f16ab095ca-c000.avro\n",
      "2022-07-14 12:57:39     590354 temp/ghrepos/141aa32f-a7d2-4b89-b48a-123cdca01005/part-00007-c2fd703c-3eb1-4168-8a97-00f16ab095ca-c000.avro\n",
      "2022-07-14 12:57:44     662250 temp/ghrepos/141aa32f-a7d2-4b89-b48a-123cdca01005/part-00008-c2fd703c-3eb1-4168-8a97-00f16ab095ca-c000.avro\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://aigithub/temp/ghrepos --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
